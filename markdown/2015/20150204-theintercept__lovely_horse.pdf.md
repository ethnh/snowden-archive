LOVELY HORSE

![img-0.jpeg](img-0.jpeg)

LOVELY HORSE v.1 TLT Task Only 144 initiative to part of CSU (formerly NDIST) and the Cyber Throne research development frame foruse a goodship. So far, we have worked towards making structured datasets available on the high side for analysis to use - this data is available within LOPS TRESSEE. We are now looking towards making use of more pronounced information things. Amma, Twitter, LOVELY HORSE sails to experience with provision of an tailored repository of unstructured information that can be used to push content of interest to individual analysis via a variety of mechanisms.

The initial LOVELY HORSE prototype can be accessed from http://lori.helow for more details.

See also: BIBLIOGR
Contents
- Problem statement
- 3.1.1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14
# To the success 

The article from MPLUS on the issue is that "provided the accurate use are selecting for acquisition must the criteria as agreed in the approvals spreadsheet, i.e. those of "sacاكمies specializing in the identification and investigation of vulnerabilities and malware", there is no need to seek authorization for each individual Twitter account." Our selection of Twitter sources is currently geebank above, but will undoubtedly increase over time.

Twitter potential sources of interest are found in Computer, security, news, and, views

## [a(b)] Processing

Initially, these articles get processed into three components:

## [a(b)] Content

The content will be the full textual content of the article. This will be stored as some sort of CSSM in a database.

## [a(b)] Notation

We would strip notations from the article such as

- Author/Source
- Outcome of submission

and used this to update a Science Discovery - information about the individual sources. For example:

- Author
- Number of articles in CSSM, C-SOMM
- Average confidence index - see feedback mechanism
- Type of unique matter linked with this content? - see defining

## [a(b)] Index

This is the important list. The aim is to index the unstructured information so that it can be linked back to

- An analysis particular interest
- An enrichment to an existing investigation

The proposed idea is to make use of tagging (defining/inducing) as 'identifying keywords'; Each article would be tagged with information that had been extracted from it. These tags could be IP addresses, domains, or any text string from within the content of the article. Effectively these tags are the output of entity extraction, and this list of tags would then be associated with that article.

Similarly, this of tags are associated with individual analyses, to define their specific interest set.

## [a(b)] We try to provide a part of tags that becomes our entity set which we're estimating from new articles coming in. How to generate this part of tags?

- Simple data would be to copy the IP addresses and domains to start off with.
- Could index a new supplement word in a long title.
- Could get analysis to provide a list of keywords they are specifically interested in.
- Could not extract keywords from existing articles to inform - for instance, do analysis tag investigations within Palante?
- Analysis should be encouraged to tag articles they read.

There is potential to link this entity extraction inhibitor to with corporate entity extraction tools that may provide more sophisticated matching.

- Cost/Key and analytically identify tags. Whole articles could be idealized until a word count generated. For particular texts appeared, say, 4 or 5 times in the current work, but not last week, then maybe that's a new trend? In which case we should add this term to the part of tags.


## [a(b)] Feedback mechanism

Important to allow analysis may ability to optimize usefulness of information. Analysis should be able to 'like' content from whichever interface they're accessing the content. First and/or then a particular article, tags from that article are automatically added to their personal tag list.

Articles can have a excellence rating assigned to them - generate some metric on the basis of number of 'like/number of' (view). Articles that have a usefulness rating over a specific threshold could be posted to all analyses. An average of the usefulness ratings across all articles from one source can be used to optimize different sources - almost becomes a result (confidence factor) in the information - should I practice upon this information!

## [a(b)] Visualization and Access

Need to be different ways analysis access and view this content.

- Palante - an enrichment to existing investigations. Similarly to the current enrichment helper, any articles that had tags which are entities within the investigation are flagged up. The content should then be viewable in a human available format within Palante.
- Adare - analysis should be aimed when a new article is tagged with a tag from that content out. How should this altering tagged 'Voxel' RSSI find?
- General search: these should be CSSM/LS. SOMM2 from one they are by used for analysis to extract across this whole experience. Would want to investigate tools that can provide Google like searching (used in investigate MIRA PEAK, NIAA-LIOMNINH).
- May need to be a database element in the enrichment, except that if I want a library to be collected.


## [a(b)] Your Thoughts

If you've got any thoughts on this initiative, please get in much other directly to [BEDACTED], or feel this to edit this section and add them below:

```
}
```

```
}
```

```
}
```

```
Ratherwell from "[BEDACTED]]
```

```
None
```

- Type
- Intervention
- Type
- Method
- Name
- Name
- Author
- Author and Statistics
```

Permanent term

## Navigation

- Name Data
- Name Types
- Text and Entities
- Text File Entities
- Text and Data
- Product name
- Product Perception
- Language
- GUYOR

Search

| Search |  |  |
| :-- | :-- | :-- |
|  |  |  |

[^0]
[^0]:    * This issue was last modified on 6 February 2012, at 09:40.
    ** This issue has been accessed 170 times.
    *** All the above 170 times were a print-in-urundance/4/improence/policy_strategy/coverage/2.7.2008 on a field-union licence from that/portion. This information is exempt under the Freedom of Information Act (FID) (FID)1 and may be exempt under other UK information legislation. Refer, see FID1, quarter or
    ** FID1 and FID2 (FID1), 6/09/09 on a field/union/4/improence/4.7.2008 on FID2 (FID2), 6/09/09 on a field/union/4/improence/4.7.2008 on FID3 (FID3), 6/09/09 on FID3 (FID3), 6/09/09 on FID3 (FID3), and growth
